Modello dei dati:
    I dati sono nel formato HDF5, Hierarchical Data Format
    Può essere pensato come yn file system contenuto e descritto in un unico file. Directories -> Groups; Files -> Datasets


Random state = 42

Architettura del modello:

    Residual Network:
        Convolutional Layer
        output_size = floor((input_size - kernel_size +2padding)/stride)
        Batch Normalization  ( sostanzialmente ricentra e riscala ) 
        ReLu 

        4 ResBlocks

        Dense (Linear) Layer
        Sigmoid

    ResBlock:
    Suppongo che l'input venga copiato:

        Una copia:

            Max Pooling  (to reduce spacial size)
            output_size = floor((input_size - kernel_size)/stride)
            1x1 Convolution

        L'altra:

            Convolutional Layer
            Batch Normalization
            ReLU
            DropOut (to help prevent overfitting, setting the values of a portion of the neurons to 0 ). We'll need to set an HyperParameter: DropOut rate

            Convolution
        
        Input uniti:
            Batch Normalization
            ReLU
            DropOut
        

FONTI:
    - RESNET PER LO STESSO PROBLEMA:  https://journals.plos.org/plosntds/article?id=10.1371/journal.pntd.0011118#pntd.0011118.ref038
                                all'interno cita fonti che potrebbero essere utili
    - Codice per RESNET: https://github.com/antonior92/ecg-age-prediction (senza sigmoide finale in quanto è un problema di regressione,  nel nostro credo andrà messo (?) )
    - Chagas Disease: https://www.sciencedirect.com/science/article/pii/S014067361060061X?via%3Dihub#cesec10
                    https://www.sciencedirect.com/science/article/pii/S0140673617316124?via%3Dihub
                    https://pmc.ncbi.nlm.nih.gov/articles/PMC358257/?page=1
    
TODO:
    - Learn about Chagas Disease
    - Learn about Deep Learning
    - Guarda ariel Informazione Multimediale / Elaborazione delle Immagini
    - Guarda SSH per connettersi
    - Save Data to .npy/.hdf5 file
    - Implement the model
        - Calculate ROC
        - Scikit k-fold e Grid Search per Hyperparameters ParameterGrid

Questions/Domande:
    Come organizzo i layer convoluzionali?
    Con quali filtri?
    Come organizzo i blocchi? Quando downsample?
    Non è meglio 4096? Almeno posso applicare stride 2

    
Info su layer:
    Conv1D:
        parametri:
            in_channels
            out_channels = numero di filtri applicati
            kernel_size = dimensione del filtro applicato
            stride
            padding
            bias = True or False
        Output shape:
            = floor(((in_shape + 2*padding - dilation * (kernel size-1)-1)/stride)+1)
    BatchNorm1D:
        Normalizza i valori tra quelli di  un mini batch
        parametri:
            features = in_channels
    MaxPool1D:
        Metodo per diminuire dimensione dell'input, selezionando solo i valori maggiori nel kernel
        parametri:
            kernel_size
            stride
            padding
        Ouput shape:
            = floor(((in_shape + 2*padding - dilation * (kernel size-1)-1)/stride)+1)
    ReLU
        Activation Function
    Dropout:
        Durante la fase di allenamento alcuni dei valori vengono posti a 0 cosi da evitare overfitting
        parametri:
            p: probabilità di porre un valore = 0
    Layer Denso
    Sigmoide
        per classificazione binaria

        